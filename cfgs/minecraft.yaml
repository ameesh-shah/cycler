env:
  _target_: 'envs.minecraft.Minecraft'
  shape: [10, 10]
  initial_state: [9, 2]
  slip_probability: 0.
classes:
  discrete: <class 'envs.minecraft.minecraft'>
logger:
  dir_name: minecraft
ltl:
  autobuild: False
  formula: GF(gold & XF(work_bench)) & (G !obstacle)
  oa_type: ldba
  rabinizer: ./rabinizer4/bin/ltl2ldba
q_learning:
  batches_per_update: 30
  batch_size: 512
  update_freq__n_episodes: 1
  temp_decay_freq__n_episodes: 25
  temp_decay_rate: .9
  min_action_temp: 0.01
  n_traj: 1500
  n_pretrain_traj: 0
  T: 100
  init_temp: .6
  lr: .00025
  iterations_per_target_update: 15
  temp_decay_type: 'exponential'
testing:
  testing_freq__n_episodes: 10
  num_rollouts: 1
gamma: .98
n_grad_updates: 1
delta: .1
n_seeds: 10
init_seed: 313
lambda: 50.0
replay_buffer_size: 50000
checkpoint_freq__n_episodes: 50
visualize: True
reward_type: 1
load_path: 0  # 0 if not pre-loading a model, otherwise a string path to the model.
model_name: "minecraft_norew"
run_name: "minecraft_trial"
num_eval_trajs: 50
baseline: "baseline"