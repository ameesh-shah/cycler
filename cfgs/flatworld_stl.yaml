env:
  _target_: 'envs.base_envs.flatworld.FlatWorld'
  render_mode: 'human'
  continuous_actions: False
classes:
  discrete: <class 'envs.flatworld.flatworld'>
  continuous: <class 'envs.flatworld.flatworld_continuous'>
logger:
  dir_name: flatworld_stl
ltl:
  autobuild: False
  formula: "G(F(y & X(F(r)))) & G~b"
  oa_type: ldba
  rabinizer: ./rabinizer4/bin/ltl2ldba
q_learning:
  batches_per_update: 5
  batch_size: 128
  update_freq__n_episodes: 1
  init_temp: .5
  temp_decay_freq__n_episodes: 100
  temp_decay_rate: .9
  temp_decay_type: 'exponential'
  min_action_temp: 0.05
  stl_lr: .00001
  reward_lr: .00001
  iterations_per_target_update: 500
  n_traj: 10000
  T: 50
testing:
  testing_freq__n_episodes: 25
  num_rollouts: 1
gamma: .97
n_grad_updates: 1
delta: .1
n_seeds: 10
init_seed: 314
replay_buffer_size: 5000
checkpoint_freq__n_episodes: 50
lambda: 1.0
